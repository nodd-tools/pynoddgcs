{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"pynoddgcs","text":"<p>Utilities for working with NOAA NODD GCS in python.   These utilities are intended as opinionated tools for interacting with GCS for the purpose of findable, accessible, interoperable and reusable open science.   By adopting common conventions for data dissemination, we not only reduce the learning curve to comprehending dataset layout, but we empower automation for combining data and further dissemination, e.g. through NCEI.</p>"},{"location":"#installation","title":"Installation","text":"<p><code>pip install pynoddgcs</code></p>"},{"location":"#contributing","title":"Contributing","text":"<p>We would love to have your contributions that improve current functionality, fix bugs, or add new features.  See the contributing guidelines for more info.</p>"},{"location":"#disclaimer","title":"Disclaimer","text":"<p>This repository is a scientific product and is not official communication of the National Oceanic and Atmospheric Administration, or the United States Department of Commerce. All NOAA GitHub project code is provided on an \u2018as is\u2019 basis and the user assumes responsibility for its use. Any claims against the Department of Commerce or Department of Commerce bureaus stemming from the use of this GitHub project will be governed by all applicable Federal law. Any reference to specific commercial products, processes, or services by service mark, trademark, manufacturer, or otherwise, does not constitute or imply their endorsement, recommendation or favoring by the Department of Commerce. The Department of Commerce seal and logo, or the seal and logo of a DOC bureau, shall not be used in any manner to imply endorsement of any commercial product or activity by DOC or the United States Government.</p>"},{"location":"CODE_OF_CONDUCT/","title":"Code of Conduct","text":"<p>This code of conduct was developed and adapted from the Atom code of conduct in October 2021. </p>"},{"location":"CODE_OF_CONDUCT/#our-pledge","title":"Our Pledge","text":"<p>In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, gender identity and expression, level of experience, nationality, personal appearance, race, religion, or sexual identity and orientation.</p>"},{"location":"CODE_OF_CONDUCT/#our-standards","title":"Our Standards","text":"<p>Examples of behavior that contributes to creating a positive environment include:</p> <ul> <li>Using welcoming and inclusive language</li> <li>Being respectful of differing viewpoints and experiences</li> <li>Gracefully accepting constructive criticism</li> <li>Focusing on what is best for the community</li> <li>Showing empathy towards other community members</li> </ul> <p>Examples of unacceptable behavior by participants include:</p> <ul> <li>The use of sexualized language or imagery and unwelcome sexual attention or advances</li> <li>Trolling, insulting/derogatory comments, and personal or political attacks</li> <li>Public or private harassment</li> <li>Publishing others' private information, such as a physical or electronic address, without explicit permission</li> <li>Other conduct which could reasonably be considered inappropriate in a professional setting</li> </ul>"},{"location":"CODE_OF_CONDUCT/#our-responsibilities","title":"Our Responsibilities","text":"<p>Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior.</p> <p>Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.</p>"},{"location":"CODE_OF_CONDUCT/#scope","title":"Scope","text":"<p>This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.</p>"},{"location":"CODE_OF_CONDUCT/#enforcement","title":"Enforcement","text":"<p>Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the project team. All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. Further details of specific enforcement policies may be posted separately.</p>"},{"location":"CODE_OF_CONDUCT/#attribution","title":"Attribution","text":"<p>This Code of Conduct is adapted from the Contributor Covenant, version 1.4, available at https://contributor-covenant.org/version/1/4</p>"},{"location":"CONTRIBUTING/","title":"Contributing Guidelines","text":"<p>Pull requests, bug reports, and all other forms of contribution are welcomed and highly encouraged! </p>"},{"location":"CONTRIBUTING/#contents","title":"Contents","text":"<ul> <li>Code of Conduct</li> <li>Bug Reports</li> <li>Feature Requests</li> <li>Submitting Pull Requests</li> <li>Code Review</li> <li>Coding Style</li> <li>Documentation</li> <li>Certificate of Origin</li> </ul> <p>This guide serves to set clear expectations for everyone involved with the project so that we can improve it together while also creating a welcoming space for everyone to participate. Following these guidelines will help ensure a positive experience for contributors and maintainers.</p>"},{"location":"CONTRIBUTING/#code-of-conduct","title":"Code of Conduct","text":"<p>Please review our Code of Conduct. It is in effect at all times. We expect it to be honored by everyone who contributes to this project. Acting like an asshole will not be tolerated.</p>"},{"location":"CONTRIBUTING/#bug-reports","title":"Bug Reports","text":"<p>Please include a minimal reproducible example with your bug report.</p>"},{"location":"CONTRIBUTING/#feature-requests","title":"Feature Requests","text":"<p>Feature requests are welcome if they fit within the scope of the project.</p> <p>Feature requests that you are willing to complete are especially welcome.  </p>"},{"location":"CONTRIBUTING/#submitting-pull-requests","title":"Submitting Pull Requests","text":"<p>Please submit an issue first and get community buy-in for proposed changes before doing any work.</p> <p>Please submit PRs in the smallest possible non-breaking chunks.</p>"},{"location":"CONTRIBUTING/#code-review","title":"Code Review","text":"<p>Any code pulled into this repo should be reviewed by a maintainer.</p> <p>Remember:</p> <ul> <li> <p>Review the code, not the author. Look for and suggest improvements without disparaging or insulting the author. Provide actionable feedback and explain your reasoning.</p> </li> <li> <p>You are not your code. When your code is critiqued, questioned, or constructively criticized, remember that you are not your code. Do not take code review personally.</p> </li> </ul>"},{"location":"CONTRIBUTING/#coding-style","title":"Coding Style","text":"<p>Follow the existing style.  We use the VSCode autopep8 linter.</p>"},{"location":"CONTRIBUTING/#documentation","title":"Documentation","text":"<p>Please include typing and docstrings for any classes.  We use numpy style docstrings.  Our auto-documentation is configured to parse this style, so please follow this convention.</p>"},{"location":"CONTRIBUTING/#testing","title":"Testing","text":"<p>Please write tests for your code.  Tests should be discoverable or runnable on a file-by-file basis.  Make sure all tests pass before submitting a pull request. </p> <pre><code>python -m unittest discover tests\n</code></pre>"},{"location":"CONTRIBUTING/#certificate-of-origin","title":"Certificate of Origin","text":"<p>WHEN YOU SUBMIT CODE TO THIS REPOSITORY, YOU AGREE TO LICENSE YOUR CODE UNDER THE LICENSE</p> <p>Developer's Certificate of Origin 1.1</p> <p>By making a contribution to this project, I certify that:</p> <ol> <li>The contribution was created in whole or in part by me and I have the right to submit it under the open source license indicated in the file; or</li> <li>The contribution is based upon previous work that, to the best of my knowledge, is covered under an appropriate open source license and I have the right under that license to submit that work with modifications, whether created in whole or in part by me, under the same open source license (unless I am permitted to submit under a different license), as indicated in the file; or</li> <li>The contribution was provided directly to me by some other person who certified (1), (2) or (3) and I have not modified it.</li> <li>I understand and agree that this project and the contribution are public and that a record of the contribution (including all personal information I submit with it, including my sign-off) is maintained indefinitely and may be redistributed consistent with this project or the open source license(s) involved.</li> </ol>"},{"location":"api/connect/","title":"Connect","text":""},{"location":"api/connect/#pynoddgcs.connect.GCS","title":"<code>GCS</code>","text":"<p>               Bases: <code>object</code></p> <p>Helper class for uploading and download files from Google Cloud Storage</p> Source code in <code>pynoddgcs/connect.py</code> <pre><code>class GCS(object):\n    \"\"\"\n    Helper class for uploading and download files from Google Cloud Storage\n    \"\"\"\n    def __init__(self):\n        self.client = storage.Client.create_anonymous_client()\n        self.authenticated = False\n\n    def download(self, bucket, source, destination = None):\n        \"\"\"\n        Downloads a file from GCS, handling both public and private buckets.\n\n        Parameters\n        ----------\n        bucket: str\n            the bucket name\n        source: str\n            the file path within the bucket\n        destination: str | None\n            the file path to which we would like to download the file.\n            default to source path within current working directory\n        \"\"\"\n        bucket = self.client.bucket(bucket)\n        blob = bucket.blob(source)\n        if destination is None:\n            destination = os.path.join(os.getcwd(), source)\n        blob.download_to_filename(destination)\n\n    def authenticate(self):\n        \"\"\"\n        Get user's default credentials on this machine.\n\n        Returns nothing, sets the values into object attributes\n        \"\"\"\n        # Use default credentials from the gcloud environment\n        try:\n            credentials, project = google.auth.default()\n        except google.auth.DefaultCredentialsError:\n            gcloud_login()\n            credentials, project = google.auth.default()\n\n        # Use the credentials to create a storage client\n        self.authenticated = True\n        self.client = storage.Client(credentials=credentials)\n\n    def check_auth(self):\n        \"\"\"\n        Authenticates the user if not already authenticated.\n        See the `authenticate` method.\n        \"\"\"\n        if not self.authenticated:\n            self.authenticate()\n\n    def upload(self, bucket, source, destination):\n        \"\"\"\n        Uploads a file to GCS\n\n        Parameters\n        ----------\n        bucket: str\n            the bucket name\n        source: str\n            the file path on the local machine\n        destination: str\n            the file path within the bucket to which we would like \n            to upload the file.\n        \"\"\"\n        # Use default credentials from the gcloud environment\n        self.check_auth()\n\n        # Upload the file\n        bucket = self.client.bucket(bucket)\n        blob = bucket.blob(destination)\n        blob.upload_from_filename(source)\n\n        print(f\"File {source} uploaded to {destination}.\")\n\n    def upload_string(self, bucket, contents, destination):\n        \"\"\"\n        Uploads a string to GCS as a file\n\n        Parameters\n        ----------\n        bucket: str\n            the bucket name\n        source: str\n            the file path on the local machine\n        destination: str\n            the file path within the bucket to which we would like \n            to upload the file.\n        \"\"\"\n        # Use default credentials from the gcloud environment\n        self.check_auth()\n\n        # Upload the file\n        bucket = self.client.bucket(bucket)\n        blob = bucket.blob(destination)\n        print(contents)\n        blob.upload_from_string(contents)\n\n        print(f\"Contents uploaded to {destination}.\")\n</code></pre>"},{"location":"api/connect/#pynoddgcs.connect.GCS.authenticate","title":"<code>authenticate()</code>","text":"<p>Get user's default credentials on this machine.</p> <p>Returns nothing, sets the values into object attributes</p> Source code in <code>pynoddgcs/connect.py</code> <pre><code>def authenticate(self):\n    \"\"\"\n    Get user's default credentials on this machine.\n\n    Returns nothing, sets the values into object attributes\n    \"\"\"\n    # Use default credentials from the gcloud environment\n    try:\n        credentials, project = google.auth.default()\n    except google.auth.DefaultCredentialsError:\n        gcloud_login()\n        credentials, project = google.auth.default()\n\n    # Use the credentials to create a storage client\n    self.authenticated = True\n    self.client = storage.Client(credentials=credentials)\n</code></pre>"},{"location":"api/connect/#pynoddgcs.connect.GCS.check_auth","title":"<code>check_auth()</code>","text":"<p>Authenticates the user if not already authenticated. See the <code>authenticate</code> method.</p> Source code in <code>pynoddgcs/connect.py</code> <pre><code>def check_auth(self):\n    \"\"\"\n    Authenticates the user if not already authenticated.\n    See the `authenticate` method.\n    \"\"\"\n    if not self.authenticated:\n        self.authenticate()\n</code></pre>"},{"location":"api/connect/#pynoddgcs.connect.GCS.download","title":"<code>download(bucket, source, destination=None)</code>","text":"<p>Downloads a file from GCS, handling both public and private buckets.</p> <p>Parameters:</p> Name Type Description Default <code>bucket</code> <p>the bucket name</p> required <code>source</code> <p>the file path within the bucket</p> required <code>destination</code> <p>the file path to which we would like to download the file. default to source path within current working directory</p> <code>None</code> Source code in <code>pynoddgcs/connect.py</code> <pre><code>def download(self, bucket, source, destination = None):\n    \"\"\"\n    Downloads a file from GCS, handling both public and private buckets.\n\n    Parameters\n    ----------\n    bucket: str\n        the bucket name\n    source: str\n        the file path within the bucket\n    destination: str | None\n        the file path to which we would like to download the file.\n        default to source path within current working directory\n    \"\"\"\n    bucket = self.client.bucket(bucket)\n    blob = bucket.blob(source)\n    if destination is None:\n        destination = os.path.join(os.getcwd(), source)\n    blob.download_to_filename(destination)\n</code></pre>"},{"location":"api/connect/#pynoddgcs.connect.GCS.upload","title":"<code>upload(bucket, source, destination)</code>","text":"<p>Uploads a file to GCS</p> <p>Parameters:</p> Name Type Description Default <code>bucket</code> <p>the bucket name</p> required <code>source</code> <p>the file path on the local machine</p> required <code>destination</code> <p>the file path within the bucket to which we would like  to upload the file.</p> required Source code in <code>pynoddgcs/connect.py</code> <pre><code>def upload(self, bucket, source, destination):\n    \"\"\"\n    Uploads a file to GCS\n\n    Parameters\n    ----------\n    bucket: str\n        the bucket name\n    source: str\n        the file path on the local machine\n    destination: str\n        the file path within the bucket to which we would like \n        to upload the file.\n    \"\"\"\n    # Use default credentials from the gcloud environment\n    self.check_auth()\n\n    # Upload the file\n    bucket = self.client.bucket(bucket)\n    blob = bucket.blob(destination)\n    blob.upload_from_filename(source)\n\n    print(f\"File {source} uploaded to {destination}.\")\n</code></pre>"},{"location":"api/connect/#pynoddgcs.connect.GCS.upload_string","title":"<code>upload_string(bucket, contents, destination)</code>","text":"<p>Uploads a string to GCS as a file</p> <p>Parameters:</p> Name Type Description Default <code>bucket</code> <p>the bucket name</p> required <code>source</code> <p>the file path on the local machine</p> required <code>destination</code> <p>the file path within the bucket to which we would like  to upload the file.</p> required Source code in <code>pynoddgcs/connect.py</code> <pre><code>def upload_string(self, bucket, contents, destination):\n    \"\"\"\n    Uploads a string to GCS as a file\n\n    Parameters\n    ----------\n    bucket: str\n        the bucket name\n    source: str\n        the file path on the local machine\n    destination: str\n        the file path within the bucket to which we would like \n        to upload the file.\n    \"\"\"\n    # Use default credentials from the gcloud environment\n    self.check_auth()\n\n    # Upload the file\n    bucket = self.client.bucket(bucket)\n    blob = bucket.blob(destination)\n    print(contents)\n    blob.upload_from_string(contents)\n\n    print(f\"Contents uploaded to {destination}.\")\n</code></pre>"},{"location":"api/connect/#pynoddgcs.connect.gcloud_login","title":"<code>gcloud_login()</code>","text":"<p>Helper method to use the gcloud API to get user credentials Requires the gcloud CLI tool to work: https://cloud.google.com/sdk/docs/install</p> <p>This method should redirect the user to a browser where they can sign in to their Google Account and grant permissions to the gcloud CLI</p> <p>Once the user is authenticated, we can use access tokens from the gcloud CLI to do gcloud stuff on the user's behalf.</p> Source code in <code>pynoddgcs/connect.py</code> <pre><code>def gcloud_login():\n    \"\"\"\n    Helper method to use the gcloud API to get user credentials\n    Requires the gcloud CLI tool to work:\n    https://cloud.google.com/sdk/docs/install\n\n    This method should redirect the user to a browser where they can sign in\n    to their Google Account and grant permissions to the gcloud CLI\n\n    Once the user is authenticated, we can use access tokens from the gcloud CLI\n    to do gcloud stuff on the user's behalf.\n    \"\"\"\n    subprocess.run(\n        [\"gcloud\", \"auth\", \"application-default\", \"login\"],\n        shell=True\n    )\n</code></pre>"},{"location":"api/connect/#pynoddgcs.connect.get_access_token","title":"<code>get_access_token()</code>","text":"<p>Gets an access token using the gcloud CLI tool We can then use this access token to perform gcloud operations on behalf of the user.</p> <p>We cache the access token for future use, as this process may make network requests which are slow.    </p> <p>Returns:</p> Name Type Description <code>access_token</code> <code>str</code> <p>an access token that can be used to perform google cloud requests.</p> Source code in <code>pynoddgcs/connect.py</code> <pre><code>def get_access_token() -&gt; str:\n    \"\"\"Gets an access token using the gcloud CLI tool\n    We can then use this access token to perform gcloud operations\n    on behalf of the user.\n\n    We cache the access token for future use, as this process\n    may make network requests which are slow.    \n\n    Returns\n    -------\n    access_token : str\n        an access token that can be used to perform google cloud requests.\n    \"\"\"\n    if CACHED_ACCESS_TOKEN is None:\n        result = subprocess.run(\n            [\"gcloud\", \"auth\", \"print-access-token\"],\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            text=True,\n            shell=True\n        )\n        if result.returncode != 0:\n            # getting the access token failed, probably because the user\n            # isn't logged in.  Log the user in, and then try again.\n            gcloud_login()\n            input('''\n                please complete gcloud login with your browser \n                and then hit the any key to continue\n            ''')\n            return get_access_token()\n        CACHED_ACCESS_TOKEN = result.stdout.strip()\n    return CACHED_ACCESS_TOKEN\n</code></pre>"},{"location":"api/publish/","title":"Publish","text":""},{"location":"api/publish/#pynoddgcs.publish.NODDCOCODataset","title":"<code>NODDCOCODataset</code>","text":"<p>               Bases: <code>object</code></p> <p>Class for validating and uploading annotations in COCO format.</p> <p>Parameters:</p> Name Type Description Default <code>coco</code> <p>a COCO-format file</p> required <code>dataset_root</code> <code>str</code> <p>the root url path for datasets, including the bucket name, etc. consider computing with <code>dataset_path</code> function.</p> required Source code in <code>pynoddgcs/publish.py</code> <pre><code>class NODDCOCODataset(object):\n    \"\"\"\n    Class for validating and uploading annotations in COCO format.\n\n    Parameters\n    ----------\n    coco: pycocotools.coco.COCO\n        a COCO-format file\n    dataset_root: str\n        the root url path for datasets, including the bucket name, etc.\n        consider computing with `dataset_path` function.\n    \"\"\"\n\n    def __init__(self, coco_file: str, dataset_root: str, bucket:str): \n        self.coco_file = coco_file\n        self.coco = pycocotools.coco.COCO(coco_file)\n        self.coco_root = os.path.split(self.coco_file)[0]\n        self.bucket = bucket\n        self.relative_gcs_path = dataset_root\n        self.gcs = GCS()\n\n    def compute_urls(self):\n        \"\"\"\n        Compute and update the urls within this COCO file to reflect the\n        expected location of the files within GCS\n        \"\"\"\n        for i, image in self.coco.imgs.items():\n            # discard the drive letter, if present\n            file_name = os.path.splitdrive(image['file_name'])[1]\n            splitfile = split_filename(file_name)\n            image['coco_url'] = join_urlpath(\n                GCS_ROOT,\n                self.bucket,\n                self.relative_gcs_path, \n                *splitfile\n            )\n\n    def unnest_filenames(self, file_separator = '_'):\n        \"\"\"\n        pycocotools doesn't appreciated \"nested\" `file_name attributes.\n        To this end, we replace the `file_name` attribute to be \"unnested\",\n        by simply replacing instances of '/' with some other separator.\n\n        Note that the URL will still potentially contain nested paths.\n        This method is idempotent if the file_name attribute is unnested.\n\n        Parameters\n        ----------\n        file_separator: str\n            the string we use to replace '/' in the `file_name`\n        \"\"\"\n        # COCO file_names should not be nested\n        for i, image in self.coco.imgs.items():\n            # discard the drive letter, if present\n            file_name = os.path.splitdrive(image['file_name'])[1]\n            splitfile = split_filename(file_name)\n            image['file_name'] = file_separator.join(splitfile)\n\n    def upload_images(self):\n        \"\"\"\n        Upload the images in this COCO metadata file to GCS.\n        The files should be located at the location specified with \n        the `file_name` attribute, either absolute or relative to \n        the location of the COCO file.\n        \"\"\"\n        for i, image in self.coco.imgs.items():\n            print(image['file_name'])\n            # discard the drive letter, if present\n            file_name = os.path.splitdrive(image['file_name'])[1]\n            splitfile = split_filename(file_name)\n            destination = join_urlpath(\n                self.relative_gcs_path, *splitfile\n            )\n            if os.path.isabs(image['file_name']):\n                source = image['file_name']\n            else:\n                source = os.path.join(self.coco_root, image['file_name'])\n            self.gcs.upload(self.bucket, source, destination)\n\n    def upload_coco(self):\n        \"\"\"\n        Upload the COCO file, but adjusted so that file urls point to files\n        in the GCS bucket.\n        \"\"\"\n        self.compute_urls()\n        self.unnest_filenames()\n        newcoco = json.dumps(self.coco.dataset)\n        destination = join_urlpath(\n            self.relative_gcs_path, 'annotations.json'\n        )\n        self.gcs.upload_string(self.bucket, newcoco, destination)\n\n    def upload(self):\n        \"\"\"\n        Upload this dataset, first the images, then the adjusted COCO file.\n        \"\"\"\n        print(\"uploading images\")\n        self.upload_images()\n        print(\"uploading coco file\")\n        self.upload_coco()\n</code></pre>"},{"location":"api/publish/#pynoddgcs.publish.NODDCOCODataset.compute_urls","title":"<code>compute_urls()</code>","text":"<p>Compute and update the urls within this COCO file to reflect the expected location of the files within GCS</p> Source code in <code>pynoddgcs/publish.py</code> <pre><code>def compute_urls(self):\n    \"\"\"\n    Compute and update the urls within this COCO file to reflect the\n    expected location of the files within GCS\n    \"\"\"\n    for i, image in self.coco.imgs.items():\n        # discard the drive letter, if present\n        file_name = os.path.splitdrive(image['file_name'])[1]\n        splitfile = split_filename(file_name)\n        image['coco_url'] = join_urlpath(\n            GCS_ROOT,\n            self.bucket,\n            self.relative_gcs_path, \n            *splitfile\n        )\n</code></pre>"},{"location":"api/publish/#pynoddgcs.publish.NODDCOCODataset.unnest_filenames","title":"<code>unnest_filenames(file_separator='_')</code>","text":"<p>pycocotools doesn't appreciated \"nested\" <code>file_name attributes. To this end, we replace the</code>file_name` attribute to be \"unnested\", by simply replacing instances of '/' with some other separator.</p> <p>Note that the URL will still potentially contain nested paths. This method is idempotent if the file_name attribute is unnested.</p> <p>Parameters:</p> Name Type Description Default <code>file_separator</code> <p>the string we use to replace '/' in the <code>file_name</code></p> <code>'_'</code> Source code in <code>pynoddgcs/publish.py</code> <pre><code>def unnest_filenames(self, file_separator = '_'):\n    \"\"\"\n    pycocotools doesn't appreciated \"nested\" `file_name attributes.\n    To this end, we replace the `file_name` attribute to be \"unnested\",\n    by simply replacing instances of '/' with some other separator.\n\n    Note that the URL will still potentially contain nested paths.\n    This method is idempotent if the file_name attribute is unnested.\n\n    Parameters\n    ----------\n    file_separator: str\n        the string we use to replace '/' in the `file_name`\n    \"\"\"\n    # COCO file_names should not be nested\n    for i, image in self.coco.imgs.items():\n        # discard the drive letter, if present\n        file_name = os.path.splitdrive(image['file_name'])[1]\n        splitfile = split_filename(file_name)\n        image['file_name'] = file_separator.join(splitfile)\n</code></pre>"},{"location":"api/publish/#pynoddgcs.publish.NODDCOCODataset.upload","title":"<code>upload()</code>","text":"<p>Upload this dataset, first the images, then the adjusted COCO file.</p> Source code in <code>pynoddgcs/publish.py</code> <pre><code>def upload(self):\n    \"\"\"\n    Upload this dataset, first the images, then the adjusted COCO file.\n    \"\"\"\n    print(\"uploading images\")\n    self.upload_images()\n    print(\"uploading coco file\")\n    self.upload_coco()\n</code></pre>"},{"location":"api/publish/#pynoddgcs.publish.NODDCOCODataset.upload_coco","title":"<code>upload_coco()</code>","text":"<p>Upload the COCO file, but adjusted so that file urls point to files in the GCS bucket.</p> Source code in <code>pynoddgcs/publish.py</code> <pre><code>def upload_coco(self):\n    \"\"\"\n    Upload the COCO file, but adjusted so that file urls point to files\n    in the GCS bucket.\n    \"\"\"\n    self.compute_urls()\n    self.unnest_filenames()\n    newcoco = json.dumps(self.coco.dataset)\n    destination = join_urlpath(\n        self.relative_gcs_path, 'annotations.json'\n    )\n    self.gcs.upload_string(self.bucket, newcoco, destination)\n</code></pre>"},{"location":"api/publish/#pynoddgcs.publish.NODDCOCODataset.upload_images","title":"<code>upload_images()</code>","text":"<p>Upload the images in this COCO metadata file to GCS. The files should be located at the location specified with  the <code>file_name</code> attribute, either absolute or relative to  the location of the COCO file.</p> Source code in <code>pynoddgcs/publish.py</code> <pre><code>def upload_images(self):\n    \"\"\"\n    Upload the images in this COCO metadata file to GCS.\n    The files should be located at the location specified with \n    the `file_name` attribute, either absolute or relative to \n    the location of the COCO file.\n    \"\"\"\n    for i, image in self.coco.imgs.items():\n        print(image['file_name'])\n        # discard the drive letter, if present\n        file_name = os.path.splitdrive(image['file_name'])[1]\n        splitfile = split_filename(file_name)\n        destination = join_urlpath(\n            self.relative_gcs_path, *splitfile\n        )\n        if os.path.isabs(image['file_name']):\n            source = image['file_name']\n        else:\n            source = os.path.join(self.coco_root, image['file_name'])\n        self.gcs.upload(self.bucket, source, destination)\n</code></pre>"},{"location":"api/publish/#pynoddgcs.publish.dataset_path","title":"<code>dataset_path(datasets_root, organization, project)</code>","text":"<p>Get a url path for uploading/downloading GCS NODD data based on the bucket, organization, etc.</p> <pre><code>&gt;&gt;&gt; dataset_path('bar', 'pickles+fish', 'project')\n'bar/pickles%2Bfish/project'\n\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>datasets_root</code> <p>the root directory within the bucket where we are hosting datasets</p> required <code>organization</code> <p>the first-level fixed-depth directory for organizing datasets</p> required <code>project</code> <p>the second-level fixed-depth directory for organizing datasets</p> required Source code in <code>pynoddgcs/publish.py</code> <pre><code>def dataset_path(datasets_root, organization, project):\n    \"\"\"\n    Get a url path for uploading/downloading GCS NODD data based on\n    the bucket, organization, etc.\n\n    ```\n    &gt;&gt;&gt; dataset_path('bar', 'pickles+fish', 'project')\n    'bar/pickles%2Bfish/project'\n\n    ```\n\n    Parameters\n    ----------\n    datasets_root: str\n        the root directory within the bucket where we are hosting datasets\n    organization: str\n        the first-level fixed-depth directory for organizing datasets\n    project: str\n        the second-level fixed-depth directory for organizing datasets\n    \"\"\"\n    return join_urlpath(\n        datasets_root, organization, project)\n</code></pre>"},{"location":"api/publish/#pynoddgcs.publish.join_urlpath","title":"<code>join_urlpath(*paths)</code>","text":"<p>Joins a bunch of strings into a slash-delimited url path.</p> <pre><code>&gt;&gt;&gt; join_urlpath('foo', 'bar', 'pickles+fish', 'project')\n'foo/bar/pickles%2Bfish/project'\n\n&gt;&gt;&gt; join_urlpath('http://foo', 'bar', 'pickles+fish', 'project')\n'http://foo/bar/pickles%2Bfish/project'\n\n&gt;&gt;&gt; join_urlpath('http://foo/bar', 'pickles+fish/project')\n'http://foo/bar/pickles%2Bfish/project'\n\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>*paths</code> <p>a variable-length list of path elements to join</p> <code>()</code> <p>Returns:</p> Name Type Description <code>url</code> <code>str</code> <p>the joined url</p> Source code in <code>pynoddgcs/publish.py</code> <pre><code>def join_urlpath(*paths):\n    \"\"\"\n    Joins a bunch of strings into a slash-delimited url path.\n\n    ``` \n    &gt;&gt;&gt; join_urlpath('foo', 'bar', 'pickles+fish', 'project')\n    'foo/bar/pickles%2Bfish/project'\n\n    &gt;&gt;&gt; join_urlpath('http://foo', 'bar', 'pickles+fish', 'project')\n    'http://foo/bar/pickles%2Bfish/project'\n\n    &gt;&gt;&gt; join_urlpath('http://foo/bar', 'pickles+fish/project')\n    'http://foo/bar/pickles%2Bfish/project'\n\n    ```\n\n    Parameters\n    ----------\n    *paths: list[str]\n        a variable-length list of path elements to join\n\n    Returns\n    -------\n    url: str\n        the joined url\n    \"\"\"\n    url = '/'.join(s.strip('/') for s in paths)\n    return urllib.parse.quote(url, safe=':/')\n</code></pre>"},{"location":"api/publish/#pynoddgcs.publish.split_filename","title":"<code>split_filename(filename)</code>","text":"<p>Splits a filename into all of its component directory structure</p> <p>Does the same thing as <code>os.path.split</code>, but completely splits the  directory structure into all parts, instead of just two (head/tail)</p> <pre><code>\n&gt;&gt;&gt; split_filename('foo/bar/pickles')\n['foo', 'bar', 'pickles']\n\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>filename</code> <p>A filename to split</p> required <p>Returns:</p> Name Type Description <code>paths</code> <code>list[str]</code> <p>The completely split list of directories  (and possibly the terminating filename)</p> Source code in <code>pynoddgcs/publish.py</code> <pre><code>def split_filename(filename):\n    \"\"\"\n    Splits a filename into all of its component directory structure\n\n    Does the same thing as `os.path.split`, but completely splits the \n    directory structure into all parts, instead of just two (head/tail)\n\n    ```\n\n    &gt;&gt;&gt; split_filename('foo/bar/pickles')\n    ['foo', 'bar', 'pickles']\n\n    ```\n\n    Parameters\n    ----------\n    filename: str\n        A filename to split\n\n    Returns\n    -------\n    paths: list[str]\n        The completely split list of directories \n        (and possibly the terminating filename)\n    \"\"\"\n    paths = []\n    tail = \"totally_arbitrary\"\n    while filename and tail:\n        filename, tail = os.path.split(filename)\n        if tail and tail != '.' and tail != '..':\n            paths.append(tail)\n    return paths[::-1]\n</code></pre>"}]}